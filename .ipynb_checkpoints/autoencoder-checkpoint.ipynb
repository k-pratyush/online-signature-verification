{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from statistics import mean\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_pickle(\"training/x_train.pkl\")\n",
    "y_train = pd.read_pickle(\"training/y_train.pkl\")\n",
    "x_test = pd.read_pickle(\"training/x_test.pkl\")\n",
    "y_test = pd.read_pickle(\"training/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xt = torch.tensor(X_train.values)\n",
    "# yt = torch.tensor(Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TensorDataset(xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dl = DataLoader(dataset, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(input_shape = (513,),activation = 'relu',units = 513),\n",
    "    tf.keras.layers.Dense(400, activation='relu'),\n",
    "    tf.keras.layers.Dense(300, activation='relu'),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(200,activation='relu'),\n",
    "    tf.keras.layers.Dense(300,activation='relu'),\n",
    "    tf.keras.layers.Dense(400,activation= 'relu'),\n",
    "    tf.keras.layers.Dense(513,activation = 'relu')\n",
    "  ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 513)               263682    \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 400)               205600    \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 400)               120400    \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 513)               205713    \n",
      "=================================================================\n",
      "Total params: 1,086,595\n",
      "Trainable params: 1,086,595\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3337 samples, validate on 249 samples\n",
      "Epoch 1/120\n",
      "3337/3337 [==============================] - 3s 780us/sample - loss: 6.4223 - accuracy: 0.0192 - val_loss: 5.5230 - val_accuracy: 0.0161\n",
      "Epoch 2/120\n",
      "3337/3337 [==============================] - 1s 432us/sample - loss: 5.3234 - accuracy: 0.0066 - val_loss: 5.0329 - val_accuracy: 0.0201\n",
      "Epoch 3/120\n",
      "3337/3337 [==============================] - 1s 378us/sample - loss: 5.0354 - accuracy: 0.0195 - val_loss: 4.8098 - val_accuracy: 0.0241\n",
      "Epoch 4/120\n",
      "3337/3337 [==============================] - 1s 393us/sample - loss: 4.9027 - accuracy: 0.0306 - val_loss: 4.7396 - val_accuracy: 0.0843\n",
      "Epoch 5/120\n",
      "3337/3337 [==============================] - 1s 393us/sample - loss: 4.7246 - accuracy: 0.1378 - val_loss: 4.6093 - val_accuracy: 0.1406\n",
      "Epoch 6/120\n",
      "3337/3337 [==============================] - 1s 383us/sample - loss: 4.7376 - accuracy: 0.4699 - val_loss: 4.6391 - val_accuracy: 0.1526\n",
      "Epoch 7/120\n",
      "3337/3337 [==============================] - 1s 392us/sample - loss: 4.6384 - accuracy: 0.2164 - val_loss: 4.4845 - val_accuracy: 0.1365\n",
      "Epoch 8/120\n",
      "3337/3337 [==============================] - 1s 404us/sample - loss: 4.6715 - accuracy: 0.6662 - val_loss: 4.4255 - val_accuracy: 0.8916\n",
      "Epoch 9/120\n",
      "3337/3337 [==============================] - 1s 416us/sample - loss: 4.4817 - accuracy: 0.7899 - val_loss: 4.3076 - val_accuracy: 0.7510\n",
      "Epoch 10/120\n",
      "3337/3337 [==============================] - 1s 389us/sample - loss: 4.4884 - accuracy: 0.9038 - val_loss: 4.2689 - val_accuracy: 0.9438\n",
      "Epoch 11/120\n",
      "3337/3337 [==============================] - 1s 378us/sample - loss: 4.2768 - accuracy: 0.9305 - val_loss: 4.2212 - val_accuracy: 0.9438\n",
      "Epoch 12/120\n",
      "3337/3337 [==============================] - 2s 474us/sample - loss: 4.2115 - accuracy: 0.9275 - val_loss: 4.0358 - val_accuracy: 0.9438\n",
      "Epoch 13/120\n",
      "3337/3337 [==============================] - 2s 493us/sample - loss: 4.1721 - accuracy: 0.9311 - val_loss: 4.0822 - val_accuracy: 0.9438\n",
      "Epoch 14/120\n",
      "3337/3337 [==============================] - 1s 438us/sample - loss: 4.1527 - accuracy: 0.9311 - val_loss: 3.9776 - val_accuracy: 0.9438\n",
      "Epoch 15/120\n",
      "3337/3337 [==============================] - 1s 388us/sample - loss: 4.1018 - accuracy: 0.9311 - val_loss: 3.9217 - val_accuracy: 0.9438\n",
      "Epoch 16/120\n",
      "3337/3337 [==============================] - 1s 376us/sample - loss: 3.9969 - accuracy: 0.9281 - val_loss: 3.8247 - val_accuracy: 0.9438\n",
      "Epoch 17/120\n",
      "3337/3337 [==============================] - 1s 393us/sample - loss: 3.9731 - accuracy: 0.9281 - val_loss: 3.6935 - val_accuracy: 0.9438\n",
      "Epoch 18/120\n",
      "3337/3337 [==============================] - 1s 410us/sample - loss: 3.7446 - accuracy: 0.9308 - val_loss: 3.5611 - val_accuracy: 0.9438\n",
      "Epoch 19/120\n",
      "3337/3337 [==============================] - 2s 516us/sample - loss: 3.6558 - accuracy: 0.9305 - val_loss: 3.4630 - val_accuracy: 0.9398\n",
      "Epoch 20/120\n",
      "3337/3337 [==============================] - 2s 633us/sample - loss: 3.6467 - accuracy: 0.9305 - val_loss: 3.5228 - val_accuracy: 0.9438\n",
      "Epoch 21/120\n",
      "3337/3337 [==============================] - 2s 480us/sample - loss: 3.6038 - accuracy: 0.9311 - val_loss: 3.4992 - val_accuracy: 0.9438\n",
      "Epoch 22/120\n",
      "3337/3337 [==============================] - 2s 491us/sample - loss: 3.5422 - accuracy: 0.9299 - val_loss: 3.4158 - val_accuracy: 0.9438\n",
      "Epoch 23/120\n",
      "3337/3337 [==============================] - 2s 464us/sample - loss: 3.5201 - accuracy: 0.9302 - val_loss: 3.3774 - val_accuracy: 0.9438\n",
      "Epoch 24/120\n",
      "3337/3337 [==============================] - 2s 552us/sample - loss: 3.4380 - accuracy: 0.9296 - val_loss: 3.2933 - val_accuracy: 0.9438\n",
      "Epoch 25/120\n",
      "3337/3337 [==============================] - 2s 608us/sample - loss: 3.4026 - accuracy: 0.9311 - val_loss: 3.2768 - val_accuracy: 0.9438\n",
      "Epoch 26/120\n",
      "3337/3337 [==============================] - 1s 449us/sample - loss: 3.4067 - accuracy: 0.9311 - val_loss: 3.2539 - val_accuracy: 0.9438\n",
      "Epoch 27/120\n",
      "3337/3337 [==============================] - 2s 482us/sample - loss: 3.5044 - accuracy: 0.9287 - val_loss: 3.6221 - val_accuracy: 0.9438\n",
      "Epoch 28/120\n",
      "3337/3337 [==============================] - 2s 566us/sample - loss: 3.5293 - accuracy: 0.9311 - val_loss: 3.2812 - val_accuracy: 0.9438\n",
      "Epoch 29/120\n",
      "3337/3337 [==============================] - 2s 517us/sample - loss: 3.3550 - accuracy: 0.9290 - val_loss: 3.2688 - val_accuracy: 0.9438\n",
      "Epoch 30/120\n",
      "3337/3337 [==============================] - 2s 588us/sample - loss: 3.2613 - accuracy: 0.9299 - val_loss: 3.3695 - val_accuracy: 0.9438\n",
      "Epoch 31/120\n",
      "3337/3337 [==============================] - 2s 555us/sample - loss: 3.3882 - accuracy: 0.9308 - val_loss: 3.1742 - val_accuracy: 0.9438\n",
      "Epoch 32/120\n",
      "3337/3337 [==============================] - 2s 465us/sample - loss: 3.3325 - accuracy: 0.9311 - val_loss: 3.1760 - val_accuracy: 0.9438\n",
      "Epoch 33/120\n",
      "3337/3337 [==============================] - 2s 510us/sample - loss: 3.2408 - accuracy: 0.9305 - val_loss: 3.1250 - val_accuracy: 0.9438\n",
      "Epoch 34/120\n",
      "3337/3337 [==============================] - 2s 535us/sample - loss: 3.2170 - accuracy: 0.9308 - val_loss: 2.9816 - val_accuracy: 0.9398\n",
      "Epoch 35/120\n",
      "3337/3337 [==============================] - 2s 482us/sample - loss: 3.1122 - accuracy: 0.9290 - val_loss: 3.0232 - val_accuracy: 0.9438\n",
      "Epoch 36/120\n",
      "3337/3337 [==============================] - 1s 447us/sample - loss: 3.0662 - accuracy: 0.9305 - val_loss: 2.9256 - val_accuracy: 0.9398\n",
      "Epoch 37/120\n",
      "3337/3337 [==============================] - 2s 618us/sample - loss: 2.9970 - accuracy: 0.9284 - val_loss: 2.9186 - val_accuracy: 0.9438\n",
      "Epoch 38/120\n",
      "3337/3337 [==============================] - 2s 472us/sample - loss: 2.9726 - accuracy: 0.9296 - val_loss: 2.8697 - val_accuracy: 0.9398\n",
      "Epoch 39/120\n",
      "3337/3337 [==============================] - 2s 475us/sample - loss: 2.9943 - accuracy: 0.9311 - val_loss: 2.8669 - val_accuracy: 0.9438\n",
      "Epoch 40/120\n",
      "3337/3337 [==============================] - 1s 399us/sample - loss: 3.0194 - accuracy: 0.9302 - val_loss: 2.8697 - val_accuracy: 0.9398\n",
      "Epoch 41/120\n",
      "3337/3337 [==============================] - 1s 396us/sample - loss: 2.9733 - accuracy: 0.9305 - val_loss: 2.7830 - val_accuracy: 0.9438\n",
      "Epoch 42/120\n",
      "3337/3337 [==============================] - 1s 408us/sample - loss: 2.9033 - accuracy: 0.9311 - val_loss: 2.8027 - val_accuracy: 0.9438\n",
      "Epoch 43/120\n",
      "3337/3337 [==============================] - 1s 419us/sample - loss: 2.8497 - accuracy: 0.9314 - val_loss: 2.7255 - val_accuracy: 0.9438\n",
      "Epoch 44/120\n",
      "3337/3337 [==============================] - 1s 392us/sample - loss: 2.8483 - accuracy: 0.9299 - val_loss: 3.3881 - val_accuracy: 0.9438\n",
      "Epoch 45/120\n",
      "3337/3337 [==============================] - 1s 412us/sample - loss: 2.9739 - accuracy: 0.9296 - val_loss: 2.7337 - val_accuracy: 0.9438\n",
      "Epoch 46/120\n",
      "3337/3337 [==============================] - 1s 434us/sample - loss: 2.7836 - accuracy: 0.9308 - val_loss: 2.7069 - val_accuracy: 0.9438\n",
      "Epoch 47/120\n",
      "3337/3337 [==============================] - 1s 418us/sample - loss: 2.8155 - accuracy: 0.9305 - val_loss: 2.6832 - val_accuracy: 0.9438\n",
      "Epoch 48/120\n",
      "3337/3337 [==============================] - 1s 406us/sample - loss: 2.7803 - accuracy: 0.9308 - val_loss: 2.6695 - val_accuracy: 0.9398\n",
      "Epoch 49/120\n",
      "3337/3337 [==============================] - 1s 376us/sample - loss: 2.7719 - accuracy: 0.9290 - val_loss: 2.6619 - val_accuracy: 0.9398\n",
      "Epoch 50/120\n",
      "3337/3337 [==============================] - 1s 388us/sample - loss: 2.7375 - accuracy: 0.9305 - val_loss: 2.6393 - val_accuracy: 0.9357\n",
      "Epoch 51/120\n",
      "3337/3337 [==============================] - 1s 403us/sample - loss: 2.7170 - accuracy: 0.9296 - val_loss: 2.6565 - val_accuracy: 0.9438\n",
      "Epoch 52/120\n",
      "3337/3337 [==============================] - 1s 406us/sample - loss: 2.7121 - accuracy: 0.9308 - val_loss: 2.5978 - val_accuracy: 0.9438\n",
      "Epoch 53/120\n",
      "3337/3337 [==============================] - 1s 399us/sample - loss: 2.7299 - accuracy: 0.9296 - val_loss: 2.6373 - val_accuracy: 0.9438\n",
      "Epoch 54/120\n",
      "3337/3337 [==============================] - 1s 398us/sample - loss: 2.7009 - accuracy: 0.9305 - val_loss: 2.6225 - val_accuracy: 0.9438\n",
      "Epoch 55/120\n",
      "3337/3337 [==============================] - 1s 405us/sample - loss: 2.6864 - accuracy: 0.9290 - val_loss: 2.5237 - val_accuracy: 0.9438\n",
      "Epoch 56/120\n",
      "3337/3337 [==============================] - 1s 399us/sample - loss: 2.6507 - accuracy: 0.9299 - val_loss: 2.5851 - val_accuracy: 0.9438\n",
      "Epoch 57/120\n",
      "3337/3337 [==============================] - 1s 386us/sample - loss: 2.6366 - accuracy: 0.9293 - val_loss: 2.5443 - val_accuracy: 0.9398\n",
      "Epoch 58/120\n",
      "3337/3337 [==============================] - 1s 388us/sample - loss: 2.6426 - accuracy: 0.9311 - val_loss: 2.5266 - val_accuracy: 0.9398\n",
      "Epoch 59/120\n",
      "3337/3337 [==============================] - 1s 406us/sample - loss: 2.6185 - accuracy: 0.9311 - val_loss: 2.5402 - val_accuracy: 0.9438\n",
      "Epoch 60/120\n",
      "3337/3337 [==============================] - 1s 406us/sample - loss: 2.6029 - accuracy: 0.9287 - val_loss: 2.5128 - val_accuracy: 0.9357\n",
      "Epoch 61/120\n",
      "3337/3337 [==============================] - 1s 397us/sample - loss: 2.5992 - accuracy: 0.9299 - val_loss: 2.4945 - val_accuracy: 0.9438\n",
      "Epoch 62/120\n",
      "3337/3337 [==============================] - 1s 423us/sample - loss: 2.6199 - accuracy: 0.9305 - val_loss: 2.5055 - val_accuracy: 0.9357\n",
      "Epoch 63/120\n",
      "3337/3337 [==============================] - 1s 434us/sample - loss: 2.5999 - accuracy: 0.9281 - val_loss: 2.4995 - val_accuracy: 0.9438\n",
      "Epoch 64/120\n",
      "3337/3337 [==============================] - 1s 414us/sample - loss: 2.5675 - accuracy: 0.9311 - val_loss: 2.4416 - val_accuracy: 0.9398\n",
      "Epoch 65/120\n",
      "3337/3337 [==============================] - 1s 433us/sample - loss: 2.5854 - accuracy: 0.9308 - val_loss: 2.4835 - val_accuracy: 0.9398\n",
      "Epoch 66/120\n",
      "3337/3337 [==============================] - 2s 653us/sample - loss: 2.5690 - accuracy: 0.9305 - val_loss: 2.4606 - val_accuracy: 0.9438\n",
      "Epoch 67/120\n",
      "3337/3337 [==============================] - 1s 424us/sample - loss: 2.5693 - accuracy: 0.9284 - val_loss: 2.4567 - val_accuracy: 0.9438\n",
      "Epoch 68/120\n",
      "3337/3337 [==============================] - 2s 506us/sample - loss: 2.5780 - accuracy: 0.9299 - val_loss: 2.4571 - val_accuracy: 0.9438\n",
      "Epoch 69/120\n",
      "3337/3337 [==============================] - 2s 473us/sample - loss: 2.5655 - accuracy: 0.9305 - val_loss: 2.4560 - val_accuracy: 0.9438\n",
      "Epoch 70/120\n",
      "3337/3337 [==============================] - 2s 544us/sample - loss: 2.5632 - accuracy: 0.9302 - val_loss: 2.4925 - val_accuracy: 0.9438\n",
      "Epoch 71/120\n",
      "3337/3337 [==============================] - 1s 388us/sample - loss: 2.5449 - accuracy: 0.9293 - val_loss: 2.4560 - val_accuracy: 0.9438\n",
      "Epoch 72/120\n",
      "3337/3337 [==============================] - 1s 377us/sample - loss: 2.5576 - accuracy: 0.9308 - val_loss: 2.4731 - val_accuracy: 0.9398\n",
      "Epoch 73/120\n",
      "3337/3337 [==============================] - 2s 554us/sample - loss: 2.5554 - accuracy: 0.9311 - val_loss: 2.4602 - val_accuracy: 0.9398\n",
      "Epoch 74/120\n",
      "3337/3337 [==============================] - 1s 410us/sample - loss: 2.5568 - accuracy: 0.9311 - val_loss: 2.4359 - val_accuracy: 0.9398\n",
      "Epoch 75/120\n",
      "3337/3337 [==============================] - 1s 404us/sample - loss: 2.5540 - accuracy: 0.9308 - val_loss: 2.4684 - val_accuracy: 0.9438\n",
      "Epoch 76/120\n",
      "3337/3337 [==============================] - 1s 410us/sample - loss: 2.5432 - accuracy: 0.9308 - val_loss: 2.4991 - val_accuracy: 0.9398\n",
      "Epoch 77/120\n",
      "3337/3337 [==============================] - 1s 414us/sample - loss: 2.5241 - accuracy: 0.9305 - val_loss: 2.4425 - val_accuracy: 0.9398\n",
      "Epoch 78/120\n",
      "3337/3337 [==============================] - 1s 418us/sample - loss: 2.4876 - accuracy: 0.9311 - val_loss: 2.3604 - val_accuracy: 0.9438\n",
      "Epoch 79/120\n",
      "3337/3337 [==============================] - 1s 423us/sample - loss: 2.4491 - accuracy: 0.9308 - val_loss: 2.3607 - val_accuracy: 0.9438\n",
      "Epoch 80/120\n",
      "3337/3337 [==============================] - 1s 400us/sample - loss: 2.4464 - accuracy: 0.9311 - val_loss: 2.4154 - val_accuracy: 0.9438\n",
      "Epoch 81/120\n",
      "3337/3337 [==============================] - 2s 697us/sample - loss: 2.5493 - accuracy: 0.9311 - val_loss: 2.4163 - val_accuracy: 0.9438\n",
      "Epoch 82/120\n",
      "3337/3337 [==============================] - 2s 542us/sample - loss: 2.4181 - accuracy: 0.9311 - val_loss: 2.3439 - val_accuracy: 0.9438\n",
      "Epoch 83/120\n",
      "3337/3337 [==============================] - 2s 494us/sample - loss: 2.3993 - accuracy: 0.9314 - val_loss: 2.2960 - val_accuracy: 0.9398\n",
      "Epoch 84/120\n",
      "3337/3337 [==============================] - 1s 441us/sample - loss: 2.4128 - accuracy: 0.9314 - val_loss: 2.3598 - val_accuracy: 0.9438\n",
      "Epoch 85/120\n",
      "3337/3337 [==============================] - 2s 461us/sample - loss: 2.5041 - accuracy: 0.9311 - val_loss: 2.6435 - val_accuracy: 0.9438\n",
      "Epoch 86/120\n",
      "3337/3337 [==============================] - 1s 432us/sample - loss: 2.4547 - accuracy: 0.9311 - val_loss: 2.4209 - val_accuracy: 0.9398\n",
      "Epoch 87/120\n",
      "3337/3337 [==============================] - 1s 422us/sample - loss: 2.4891 - accuracy: 0.9281 - val_loss: 2.2867 - val_accuracy: 0.9398\n",
      "Epoch 88/120\n",
      "3337/3337 [==============================] - 1s 412us/sample - loss: 2.4053 - accuracy: 0.9299 - val_loss: 2.3194 - val_accuracy: 0.9357\n",
      "Epoch 89/120\n",
      "3337/3337 [==============================] - 1s 395us/sample - loss: 2.3913 - accuracy: 0.9305 - val_loss: 2.3474 - val_accuracy: 0.9438\n",
      "Epoch 90/120\n",
      "3337/3337 [==============================] - 1s 430us/sample - loss: 2.3855 - accuracy: 0.9278 - val_loss: 2.2974 - val_accuracy: 0.9438\n",
      "Epoch 91/120\n",
      "3337/3337 [==============================] - 1s 436us/sample - loss: 2.3604 - accuracy: 0.9308 - val_loss: 2.2953 - val_accuracy: 0.9438\n",
      "Epoch 92/120\n",
      "3337/3337 [==============================] - 2s 518us/sample - loss: 2.4040 - accuracy: 0.9299 - val_loss: 2.2900 - val_accuracy: 0.9438\n",
      "Epoch 93/120\n",
      "3337/3337 [==============================] - 1s 445us/sample - loss: 2.3185 - accuracy: 0.9299 - val_loss: 2.2145 - val_accuracy: 0.9438\n",
      "Epoch 94/120\n",
      "3337/3337 [==============================] - 1s 440us/sample - loss: 2.2924 - accuracy: 0.9293 - val_loss: 2.2411 - val_accuracy: 0.9357\n",
      "Epoch 95/120\n",
      "3337/3337 [==============================] - 2s 570us/sample - loss: 2.2649 - accuracy: 0.9287 - val_loss: 2.1876 - val_accuracy: 0.9398\n",
      "Epoch 96/120\n",
      "3337/3337 [==============================] - 2s 493us/sample - loss: 2.2603 - accuracy: 0.9293 - val_loss: 2.1881 - val_accuracy: 0.9438\n",
      "Epoch 97/120\n",
      "3337/3337 [==============================] - 2s 541us/sample - loss: 2.2648 - accuracy: 0.9308 - val_loss: 2.1660 - val_accuracy: 0.9398\n",
      "Epoch 98/120\n",
      "3337/3337 [==============================] - 2s 467us/sample - loss: 2.2862 - accuracy: 0.9314 - val_loss: 2.1818 - val_accuracy: 0.9438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/120\n",
      "3337/3337 [==============================] - 1s 429us/sample - loss: 2.2642 - accuracy: 0.9308 - val_loss: 2.1866 - val_accuracy: 0.9438\n",
      "Epoch 100/120\n",
      "3337/3337 [==============================] - 1s 427us/sample - loss: 2.3869 - accuracy: 0.9311 - val_loss: 2.2871 - val_accuracy: 0.9438\n",
      "Epoch 101/120\n",
      "3337/3337 [==============================] - 2s 482us/sample - loss: 2.2984 - accuracy: 0.9311 - val_loss: 2.1966 - val_accuracy: 0.9438\n",
      "Epoch 102/120\n",
      "3337/3337 [==============================] - 2s 486us/sample - loss: 2.2889 - accuracy: 0.9311 - val_loss: 2.4451 - val_accuracy: 0.9438\n",
      "Epoch 103/120\n",
      "3337/3337 [==============================] - 1s 429us/sample - loss: 2.2980 - accuracy: 0.9308 - val_loss: 2.2033 - val_accuracy: 0.9438\n",
      "Epoch 104/120\n",
      "3337/3337 [==============================] - 2s 500us/sample - loss: 2.2792 - accuracy: 0.9311 - val_loss: 2.1799 - val_accuracy: 0.9438\n",
      "Epoch 105/120\n",
      "3337/3337 [==============================] - 1s 440us/sample - loss: 2.3064 - accuracy: 0.9311 - val_loss: 2.2856 - val_accuracy: 0.9438\n",
      "Epoch 106/120\n",
      "3337/3337 [==============================] - 2s 654us/sample - loss: 2.2834 - accuracy: 0.9311 - val_loss: 2.1491 - val_accuracy: 0.9438\n",
      "Epoch 107/120\n",
      "3337/3337 [==============================] - 2s 516us/sample - loss: 2.3035 - accuracy: 0.9311 - val_loss: 2.2648 - val_accuracy: 0.9438\n",
      "Epoch 108/120\n",
      "3337/3337 [==============================] - 2s 636us/sample - loss: 2.2844 - accuracy: 0.9311 - val_loss: 2.2009 - val_accuracy: 0.9438\n",
      "Epoch 109/120\n",
      "3337/3337 [==============================] - 2s 513us/sample - loss: 2.3508 - accuracy: 0.9311 - val_loss: 2.2048 - val_accuracy: 0.9438\n",
      "Epoch 110/120\n",
      "3337/3337 [==============================] - 2s 589us/sample - loss: 2.2564 - accuracy: 0.9311 - val_loss: 2.1476 - val_accuracy: 0.9438\n",
      "Epoch 111/120\n",
      "3337/3337 [==============================] - 2s 455us/sample - loss: 2.2339 - accuracy: 0.9311 - val_loss: 2.1893 - val_accuracy: 0.9438\n",
      "Epoch 112/120\n",
      "3337/3337 [==============================] - 2s 483us/sample - loss: 2.2514 - accuracy: 0.9308 - val_loss: 2.1813 - val_accuracy: 0.9438\n",
      "Epoch 113/120\n",
      "3337/3337 [==============================] - 2s 525us/sample - loss: 2.2616 - accuracy: 0.9311 - val_loss: 2.3094 - val_accuracy: 0.9438\n",
      "Epoch 114/120\n",
      "3337/3337 [==============================] - 2s 455us/sample - loss: 2.3908 - accuracy: 0.9311 - val_loss: 2.2099 - val_accuracy: 0.9398\n",
      "Epoch 115/120\n",
      "3337/3337 [==============================] - 2s 458us/sample - loss: 2.3025 - accuracy: 0.9305 - val_loss: 2.2159 - val_accuracy: 0.9438\n",
      "Epoch 116/120\n",
      "3337/3337 [==============================] - 2s 457us/sample - loss: 2.3560 - accuracy: 0.9305 - val_loss: 2.2473 - val_accuracy: 0.9438\n",
      "Epoch 117/120\n",
      "3337/3337 [==============================] - 2s 528us/sample - loss: 2.4216 - accuracy: 0.9311 - val_loss: 2.3835 - val_accuracy: 0.9438\n",
      "Epoch 118/120\n",
      "3337/3337 [==============================] - 1s 419us/sample - loss: 2.4897 - accuracy: 0.9311 - val_loss: 2.6755 - val_accuracy: 0.9438\n",
      "Epoch 119/120\n",
      "3337/3337 [==============================] - 1s 400us/sample - loss: 2.5478 - accuracy: 0.9293 - val_loss: 2.1757 - val_accuracy: 0.9438\n",
      "Epoch 120/120\n",
      "3337/3337 [==============================] - 1s 445us/sample - loss: 2.2938 - accuracy: 0.9299 - val_loss: 2.1745 - val_accuracy: 0.9438\n"
     ]
    }
   ],
   "source": [
    "auto_model = autoencoder()\n",
    "historty = auto_model.fit(x_train.values,x_train.values,epochs=120,validation_data=(x_test.values[:249], x_test.values[:249]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3337, 513)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431/1431 [==============================] - 0s 126us/sample - loss: 2.2479 - accuracy: 0.9364\n"
     ]
    }
   ],
   "source": [
    "results = auto_model.evaluate(x_test, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = auto_model.predict(x_test[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "input_s= Input(shape=(513,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 513)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 400)               205600    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 400)               120400    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 513)               205713    \n",
      "=================================================================\n",
      "Total params: 812,813\n",
      "Trainable params: 812,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoded = Dense(units=400, activation='relu')(input_s)\n",
    "encoded = Dense(units=300, activation='relu')(encoded)\n",
    "encoded = Dense(units=200, activation='relu')(encoded)\n",
    "encoded = Dense(units=100, activation='relu')(encoded)\n",
    "decoded = Dense(units=200, activation='relu')(encoded)\n",
    "decoded = Dense(units=300, activation='relu')(decoded)\n",
    "decoded = Dense(units=400, activation='relu')(decoded)\n",
    "decoded = Dense(units=513, activation='relu')(decoded)\n",
    "autoencoder=Model(input_s, decoded)\n",
    "# encoder = Model(input_s, encoded)\n",
    "autoencoder.summary()\n",
    "# encoder.summary()\n",
    "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredLogarithmicError(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3337 samples, validate on 1431 samples\n",
      "Epoch 1/100\n",
      "3337/3337 [==============================] - 2s 707us/step - loss: 7.0441 - accuracy: 0.3111 - val_loss: 6.2879 - val_accuracy: 0.7372\n",
      "Epoch 2/100\n",
      "3337/3337 [==============================] - 2s 730us/step - loss: 6.2570 - accuracy: 0.7752 - val_loss: 6.1597 - val_accuracy: 0.9364\n",
      "Epoch 3/100\n",
      "3337/3337 [==============================] - 2s 662us/step - loss: 5.7051 - accuracy: 0.9302 - val_loss: 5.4928 - val_accuracy: 0.9364\n",
      "Epoch 4/100\n",
      "3337/3337 [==============================] - 2s 624us/step - loss: 5.5702 - accuracy: 0.9305 - val_loss: 5.5800 - val_accuracy: 0.9287\n",
      "Epoch 5/100\n",
      "3337/3337 [==============================] - 2s 700us/step - loss: 5.7076 - accuracy: 0.9299 - val_loss: 5.7239 - val_accuracy: 0.9364\n",
      "Epoch 6/100\n",
      "3337/3337 [==============================] - 2s 670us/step - loss: 5.5025 - accuracy: 0.9308 - val_loss: 5.3064 - val_accuracy: 0.9364\n",
      "Epoch 7/100\n",
      "3337/3337 [==============================] - 2s 659us/step - loss: 5.6054 - accuracy: 0.9278 - val_loss: 5.2659 - val_accuracy: 0.9364\n",
      "Epoch 8/100\n",
      "3337/3337 [==============================] - 2s 708us/step - loss: 5.1792 - accuracy: 0.9305 - val_loss: 5.4304 - val_accuracy: 0.9364\n",
      "Epoch 9/100\n",
      "3337/3337 [==============================] - 3s 814us/step - loss: 5.1922 - accuracy: 0.9293 - val_loss: 5.1247 - val_accuracy: 0.9364\n",
      "Epoch 10/100\n",
      "3337/3337 [==============================] - 3s 837us/step - loss: 5.0520 - accuracy: 0.9293 - val_loss: 5.0342 - val_accuracy: 0.9364\n",
      "Epoch 11/100\n",
      "3337/3337 [==============================] - 3s 789us/step - loss: 4.9733 - accuracy: 0.9290 - val_loss: 4.8654 - val_accuracy: 0.9287\n",
      "Epoch 12/100\n",
      "3337/3337 [==============================] - 3s 765us/step - loss: 5.0519 - accuracy: 0.9308 - val_loss: 5.3572 - val_accuracy: 0.9364\n",
      "Epoch 13/100\n",
      "3337/3337 [==============================] - 2s 726us/step - loss: 5.3137 - accuracy: 0.9311 - val_loss: 5.2990 - val_accuracy: 0.9364\n",
      "Epoch 14/100\n",
      "3337/3337 [==============================] - 2s 728us/step - loss: 5.2175 - accuracy: 0.9299 - val_loss: 4.6014 - val_accuracy: 0.9287\n",
      "Epoch 15/100\n",
      "3337/3337 [==============================] - 2s 725us/step - loss: 4.6764 - accuracy: 0.9269 - val_loss: 4.7240 - val_accuracy: 0.9287\n",
      "Epoch 16/100\n",
      "3337/3337 [==============================] - 3s 843us/step - loss: 4.8888 - accuracy: 0.9296 - val_loss: 5.0459 - val_accuracy: 0.9364\n",
      "Epoch 17/100\n",
      "3337/3337 [==============================] - 2s 747us/step - loss: 5.0803 - accuracy: 0.9308 - val_loss: 4.8643 - val_accuracy: 0.9287\n",
      "Epoch 18/100\n",
      "3337/3337 [==============================] - 3s 759us/step - loss: 4.8513 - accuracy: 0.9251 - val_loss: 4.6374 - val_accuracy: 0.9287\n",
      "Epoch 19/100\n",
      "3337/3337 [==============================] - 2s 579us/step - loss: 4.9488 - accuracy: 0.9248 - val_loss: 4.8206 - val_accuracy: 0.9294\n",
      "Epoch 20/100\n",
      "3337/3337 [==============================] - 2s 526us/step - loss: 4.7022 - accuracy: 0.9272 - val_loss: 4.3859 - val_accuracy: 0.9287\n",
      "Epoch 21/100\n",
      "3337/3337 [==============================] - 2s 555us/step - loss: 4.3251 - accuracy: 0.9278 - val_loss: 4.2741 - val_accuracy: 0.9364\n",
      "Epoch 22/100\n",
      "3337/3337 [==============================] - 2s 562us/step - loss: 4.2260 - accuracy: 0.9293 - val_loss: 4.2250 - val_accuracy: 0.9350\n",
      "Epoch 23/100\n",
      "3337/3337 [==============================] - 2s 536us/step - loss: 4.1270 - accuracy: 0.9275 - val_loss: 4.0677 - val_accuracy: 0.9350\n",
      "Epoch 24/100\n",
      "3337/3337 [==============================] - 2s 546us/step - loss: 4.1467 - accuracy: 0.9296 - val_loss: 4.1722 - val_accuracy: 0.9322\n",
      "Epoch 25/100\n",
      "3337/3337 [==============================] - 2s 532us/step - loss: 4.1559 - accuracy: 0.9266 - val_loss: 4.0991 - val_accuracy: 0.9364\n",
      "Epoch 26/100\n",
      "3337/3337 [==============================] - 2s 532us/step - loss: 4.0401 - accuracy: 0.9275 - val_loss: 3.9417 - val_accuracy: 0.9294\n",
      "Epoch 27/100\n",
      "3337/3337 [==============================] - 2s 530us/step - loss: 4.1012 - accuracy: 0.9275 - val_loss: 4.2346 - val_accuracy: 0.9294\n",
      "Epoch 28/100\n",
      "3337/3337 [==============================] - 2s 526us/step - loss: 4.2614 - accuracy: 0.9302 - val_loss: 4.2942 - val_accuracy: 0.9364\n",
      "Epoch 29/100\n",
      "3337/3337 [==============================] - 2s 553us/step - loss: 4.0639 - accuracy: 0.9284 - val_loss: 3.9982 - val_accuracy: 0.9287\n",
      "Epoch 30/100\n",
      "3337/3337 [==============================] - 2s 525us/step - loss: 4.0224 - accuracy: 0.9284 - val_loss: 4.0015 - val_accuracy: 0.9364\n",
      "Epoch 31/100\n",
      "3337/3337 [==============================] - 2s 521us/step - loss: 4.0313 - accuracy: 0.9308 - val_loss: 3.9454 - val_accuracy: 0.9364\n",
      "Epoch 32/100\n",
      "3337/3337 [==============================] - 2s 525us/step - loss: 4.1360 - accuracy: 0.9287 - val_loss: 4.1080 - val_accuracy: 0.9364\n",
      "Epoch 33/100\n",
      "3337/3337 [==============================] - 2s 520us/step - loss: 4.0312 - accuracy: 0.9308 - val_loss: 3.9646 - val_accuracy: 0.9301\n",
      "Epoch 34/100\n",
      "3337/3337 [==============================] - 2s 548us/step - loss: 3.9355 - accuracy: 0.9278 - val_loss: 3.8486 - val_accuracy: 0.9343\n",
      "Epoch 35/100\n",
      "3337/3337 [==============================] - 2s 535us/step - loss: 3.8626 - accuracy: 0.9311 - val_loss: 3.8766 - val_accuracy: 0.9364\n",
      "Epoch 36/100\n",
      "3337/3337 [==============================] - 2s 520us/step - loss: 3.8533 - accuracy: 0.9287 - val_loss: 3.8306 - val_accuracy: 0.9364\n",
      "Epoch 37/100\n",
      "3337/3337 [==============================] - 2s 524us/step - loss: 3.8090 - accuracy: 0.9269 - val_loss: 4.2434 - val_accuracy: 0.9294\n",
      "Epoch 38/100\n",
      "3337/3337 [==============================] - 2s 522us/step - loss: 4.0399 - accuracy: 0.9269 - val_loss: 3.8235 - val_accuracy: 0.9329\n",
      "Epoch 39/100\n",
      "3337/3337 [==============================] - 2s 519us/step - loss: 3.8486 - accuracy: 0.9305 - val_loss: 3.8001 - val_accuracy: 0.9364\n",
      "Epoch 40/100\n",
      "3337/3337 [==============================] - 2s 569us/step - loss: 3.7964 - accuracy: 0.9311 - val_loss: 3.8134 - val_accuracy: 0.9364\n",
      "Epoch 41/100\n",
      "3337/3337 [==============================] - 2s 596us/step - loss: 3.7839 - accuracy: 0.9299 - val_loss: 3.8032 - val_accuracy: 0.9364\n",
      "Epoch 42/100\n",
      "3337/3337 [==============================] - 2s 606us/step - loss: 3.7396 - accuracy: 0.9302 - val_loss: 3.7015 - val_accuracy: 0.9364\n",
      "Epoch 43/100\n",
      "3337/3337 [==============================] - 2s 634us/step - loss: 3.7393 - accuracy: 0.9293 - val_loss: 3.7218 - val_accuracy: 0.9294\n",
      "Epoch 44/100\n",
      "3337/3337 [==============================] - 2s 581us/step - loss: 3.7159 - accuracy: 0.9278 - val_loss: 3.9267 - val_accuracy: 0.9364\n",
      "Epoch 45/100\n",
      "3337/3337 [==============================] - 2s 588us/step - loss: 3.7452 - accuracy: 0.9311 - val_loss: 3.7164 - val_accuracy: 0.9364\n",
      "Epoch 46/100\n",
      "3337/3337 [==============================] - 2s 612us/step - loss: 3.6684 - accuracy: 0.9293 - val_loss: 3.6557 - val_accuracy: 0.9364\n",
      "Epoch 47/100\n",
      "3337/3337 [==============================] - 2s 626us/step - loss: 3.7048 - accuracy: 0.9299 - val_loss: 3.6854 - val_accuracy: 0.9364\n",
      "Epoch 48/100\n",
      "3337/3337 [==============================] - 2s 628us/step - loss: 3.6695 - accuracy: 0.9308 - val_loss: 3.6317 - val_accuracy: 0.9364\n",
      "Epoch 49/100\n",
      "3337/3337 [==============================] - 2s 610us/step - loss: 3.6648 - accuracy: 0.9305 - val_loss: 3.6926 - val_accuracy: 0.9357\n",
      "Epoch 50/100\n",
      "3337/3337 [==============================] - 2s 560us/step - loss: 3.7293 - accuracy: 0.9311 - val_loss: 3.6553 - val_accuracy: 0.9364\n",
      "Epoch 51/100\n",
      "3337/3337 [==============================] - 2s 521us/step - loss: 3.7210 - accuracy: 0.9296 - val_loss: 3.6135 - val_accuracy: 0.9357\n",
      "Epoch 52/100\n",
      "3337/3337 [==============================] - 2s 525us/step - loss: 3.8016 - accuracy: 0.9290 - val_loss: 3.8960 - val_accuracy: 0.9357\n",
      "Epoch 53/100\n",
      "3337/3337 [==============================] - 2s 525us/step - loss: 3.7850 - accuracy: 0.9275 - val_loss: 3.9462 - val_accuracy: 0.9287\n",
      "Epoch 54/100\n",
      "3337/3337 [==============================] - 2s 522us/step - loss: 3.6953 - accuracy: 0.9281 - val_loss: 3.5998 - val_accuracy: 0.9350\n",
      "Epoch 55/100\n",
      "3337/3337 [==============================] - 2s 516us/step - loss: 3.6027 - accuracy: 0.9290 - val_loss: 3.6353 - val_accuracy: 0.9364\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3337/3337 [==============================] - 2s 538us/step - loss: 3.5969 - accuracy: 0.9311 - val_loss: 3.5360 - val_accuracy: 0.9350\n",
      "Epoch 57/100\n",
      "3337/3337 [==============================] - 2s 525us/step - loss: 3.5391 - accuracy: 0.9305 - val_loss: 3.5951 - val_accuracy: 0.9287\n",
      "Epoch 58/100\n",
      "3337/3337 [==============================] - 2s 517us/step - loss: 3.6915 - accuracy: 0.9311 - val_loss: 3.7113 - val_accuracy: 0.9364\n",
      "Epoch 59/100\n",
      "3337/3337 [==============================] - 2s 516us/step - loss: 3.5379 - accuracy: 0.9290 - val_loss: 4.3595 - val_accuracy: 0.9287\n",
      "Epoch 60/100\n",
      "3337/3337 [==============================] - 2s 516us/step - loss: 4.0715 - accuracy: 0.9251 - val_loss: 3.7818 - val_accuracy: 0.9287\n",
      "Epoch 61/100\n",
      "3337/3337 [==============================] - 2s 523us/step - loss: 3.6766 - accuracy: 0.9257 - val_loss: 3.6611 - val_accuracy: 0.9294\n",
      "Epoch 62/100\n",
      "3337/3337 [==============================] - 2s 526us/step - loss: 3.5970 - accuracy: 0.9251 - val_loss: 3.4834 - val_accuracy: 0.9301\n",
      "Epoch 63/100\n",
      "3337/3337 [==============================] - 2s 513us/step - loss: 3.4917 - accuracy: 0.9275 - val_loss: 3.4205 - val_accuracy: 0.9336\n",
      "Epoch 64/100\n",
      "3337/3337 [==============================] - 2s 521us/step - loss: 3.3981 - accuracy: 0.9272 - val_loss: 3.3571 - val_accuracy: 0.9336\n",
      "Epoch 65/100\n",
      "3337/3337 [==============================] - 2s 535us/step - loss: 3.3887 - accuracy: 0.9272 - val_loss: 3.3639 - val_accuracy: 0.9322\n",
      "Epoch 66/100\n",
      "3337/3337 [==============================] - 2s 531us/step - loss: 3.3809 - accuracy: 0.9266 - val_loss: 3.3943 - val_accuracy: 0.9308\n",
      "Epoch 67/100\n",
      "3337/3337 [==============================] - 2s 520us/step - loss: 3.3958 - accuracy: 0.9266 - val_loss: 3.3883 - val_accuracy: 0.9294\n",
      "Epoch 68/100\n",
      "3337/3337 [==============================] - 2s 517us/step - loss: 3.3972 - accuracy: 0.9284 - val_loss: 3.4642 - val_accuracy: 0.9350\n",
      "Epoch 69/100\n",
      "3337/3337 [==============================] - 2s 526us/step - loss: 3.3822 - accuracy: 0.9287 - val_loss: 3.4160 - val_accuracy: 0.9343\n",
      "Epoch 70/100\n",
      "3337/3337 [==============================] - 2s 518us/step - loss: 3.4777 - accuracy: 0.9290 - val_loss: 3.6980 - val_accuracy: 0.9364\n",
      "Epoch 71/100\n",
      "3337/3337 [==============================] - 2s 512us/step - loss: 3.5219 - accuracy: 0.9284 - val_loss: 3.4105 - val_accuracy: 0.9343\n",
      "Epoch 72/100\n",
      "3337/3337 [==============================] - 2s 527us/step - loss: 3.4842 - accuracy: 0.9272 - val_loss: 3.5947 - val_accuracy: 0.9287\n",
      "Epoch 73/100\n",
      "3337/3337 [==============================] - 2s 519us/step - loss: 3.5019 - accuracy: 0.9275 - val_loss: 3.3651 - val_accuracy: 0.9364\n",
      "Epoch 74/100\n",
      "3337/3337 [==============================] - 2s 540us/step - loss: 3.3790 - accuracy: 0.9284 - val_loss: 3.3473 - val_accuracy: 0.9343\n",
      "Epoch 75/100\n",
      "3337/3337 [==============================] - 2s 521us/step - loss: 3.4199 - accuracy: 0.9308 - val_loss: 3.3332 - val_accuracy: 0.9364\n",
      "Epoch 76/100\n",
      "3337/3337 [==============================] - 2s 516us/step - loss: 3.4659 - accuracy: 0.9302 - val_loss: 3.6036 - val_accuracy: 0.9364\n",
      "Epoch 77/100\n",
      "3337/3337 [==============================] - 2s 519us/step - loss: 3.5074 - accuracy: 0.9272 - val_loss: 3.3255 - val_accuracy: 0.9287\n",
      "Epoch 78/100\n",
      "3337/3337 [==============================] - 2s 520us/step - loss: 3.4508 - accuracy: 0.9269 - val_loss: 3.6314 - val_accuracy: 0.9294\n",
      "Epoch 79/100\n",
      "3337/3337 [==============================] - 2s 521us/step - loss: 3.5057 - accuracy: 0.9245 - val_loss: 3.4222 - val_accuracy: 0.9266\n",
      "Epoch 80/100\n",
      "3337/3337 [==============================] - 2s 517us/step - loss: 3.3750 - accuracy: 0.9206 - val_loss: 3.3739 - val_accuracy: 0.9301\n",
      "Epoch 81/100\n",
      "3337/3337 [==============================] - 2s 519us/step - loss: 3.4121 - accuracy: 0.9203 - val_loss: 3.4369 - val_accuracy: 0.9287\n",
      "Epoch 82/100\n",
      "3337/3337 [==============================] - 2s 519us/step - loss: 3.5160 - accuracy: 0.9281 - val_loss: 3.7450 - val_accuracy: 0.9364\n",
      "Epoch 83/100\n",
      "3337/3337 [==============================] - 2s 546us/step - loss: 3.4377 - accuracy: 0.9260 - val_loss: 3.3613 - val_accuracy: 0.9287\n",
      "Epoch 84/100\n",
      "3337/3337 [==============================] - 2s 535us/step - loss: 3.3602 - accuracy: 0.9269 - val_loss: 3.4381 - val_accuracy: 0.9364\n",
      "Epoch 85/100\n",
      "3337/3337 [==============================] - 2s 603us/step - loss: 3.4123 - accuracy: 0.9287 - val_loss: 3.3663 - val_accuracy: 0.9364\n",
      "Epoch 86/100\n",
      "3337/3337 [==============================] - 2s 529us/step - loss: 3.3603 - accuracy: 0.9302 - val_loss: 3.5010 - val_accuracy: 0.9364\n",
      "Epoch 87/100\n",
      "3337/3337 [==============================] - 2s 532us/step - loss: 3.4084 - accuracy: 0.9290 - val_loss: 3.3679 - val_accuracy: 0.9287\n",
      "Epoch 88/100\n",
      "3337/3337 [==============================] - 2s 524us/step - loss: 3.3328 - accuracy: 0.9275 - val_loss: 3.3604 - val_accuracy: 0.9364\n",
      "Epoch 89/100\n",
      "3337/3337 [==============================] - 2s 523us/step - loss: 3.3423 - accuracy: 0.9311 - val_loss: 3.2985 - val_accuracy: 0.9364\n",
      "Epoch 90/100\n",
      "3337/3337 [==============================] - 2s 565us/step - loss: 3.3849 - accuracy: 0.9275 - val_loss: 3.3157 - val_accuracy: 0.9350\n",
      "Epoch 91/100\n",
      "3337/3337 [==============================] - 2s 523us/step - loss: 3.4325 - accuracy: 0.9311 - val_loss: 3.5625 - val_accuracy: 0.9364\n",
      "Epoch 92/100\n",
      "3337/3337 [==============================] - 2s 538us/step - loss: 3.4782 - accuracy: 0.9284 - val_loss: 3.3818 - val_accuracy: 0.9287\n",
      "Epoch 93/100\n",
      "3337/3337 [==============================] - 2s 530us/step - loss: 3.3451 - accuracy: 0.9248 - val_loss: 3.3200 - val_accuracy: 0.9287\n",
      "Epoch 94/100\n",
      "3337/3337 [==============================] - 2s 526us/step - loss: 3.2997 - accuracy: 0.9272 - val_loss: 3.2987 - val_accuracy: 0.9294\n",
      "Epoch 95/100\n",
      "3337/3337 [==============================] - 2s 529us/step - loss: 3.2659 - accuracy: 0.9299 - val_loss: 3.2769 - val_accuracy: 0.9364\n",
      "Epoch 96/100\n",
      "3337/3337 [==============================] - 2s 536us/step - loss: 3.2789 - accuracy: 0.9302 - val_loss: 3.3506 - val_accuracy: 0.9364\n",
      "Epoch 97/100\n",
      "3337/3337 [==============================] - 2s 524us/step - loss: 3.3860 - accuracy: 0.9311 - val_loss: 3.2667 - val_accuracy: 0.9308\n",
      "Epoch 98/100\n",
      "3337/3337 [==============================] - 2s 555us/step - loss: 3.3851 - accuracy: 0.9299 - val_loss: 3.2606 - val_accuracy: 0.9287\n",
      "Epoch 99/100\n",
      "3337/3337 [==============================] - 2s 527us/step - loss: 3.3522 - accuracy: 0.9299 - val_loss: 3.7770 - val_accuracy: 0.9364\n",
      "Epoch 100/100\n",
      "3337/3337 [==============================] - 2s 533us/step - loss: 3.4837 - accuracy: 0.9275 - val_loss: 3.4320 - val_accuracy: 0.9287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x156d130d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,                \n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
